---
jurisdiction: EU
law: DSA
effective_start: 2024-02-17
source_url: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A32022R2065
---

# Digital Services Act (extract)

## Article 28 - Risk assessment for very large online platforms and very large online search engines

1. Providers of very large online platforms and very large online search engines shall diligently identify, analyse and assess any systemic risks stemming from the functioning and use of their service in the Union, that may arise, in particular:
   
   (a) from the way in which their algorithmic systems amplify certain risks, such as:
       - illegal content in areas such as child sexual abuse, terrorist content, illegal hate speech, commercial fraud and counterfeiting of products;
       - risks for the exercise of fundamental rights, in particular the rights to human dignity, freedom of expression and information, the right to private and family life, the rights of the child and consumer protection, the right to non-discrimination and the rights of women and of persons belonging to vulnerable groups;
   
   (b) from their use by recipients of the service, including misuse through:
       - the submission of illegal content, including by inauthentic use or automated exploitation of the service;
       - inauthentic or abusive behavior that may lead to the rapid and wide dissemination of information that is illegal content or incompatible with their terms and conditions;

## Article 34 - Transparency obligations for recommender systems

1. Providers of online platforms that use recommender systems shall set out in their terms and conditions, in plain and intelligible language, the main parameters used in their recommender systems, as well as any options for the recipients of the service to modify or influence those main parameters.

## Article 35 - Additional risk mitigation measures for very large online platforms and very large online search engines

1. Where the risk assessment carried out in accordance with Article 28 reveals one or more systemic risks, providers of very large online platforms and very large online search engines shall put in place reasonable, proportionate and effective mitigation measures, tailored to the specific systemic risks identified.

2. The measures referred to in paragraph 1 may include, in particular:
   (a) adapting content moderation or other relevant systems, processes or mechanisms, including by adapting automated tools or increasing human oversight;
   (b) adapting decision-making processes;
   (c) adapting the design, features or functioning of their services or their app, including the recommender systems;
   (d) taking action related to advertising systems;
   (e) pursuing awareness-raising initiatives and adapting interfaces to enable user empowerment and literacy.

## Article 24 - Notification of illegal content

1. Providers of hosting services shall put in place mechanisms that allow any individual or entity to notify them of the presence on their service of specific items of information that the individual or entity considers to be illegal content.

2. The mechanisms referred to in paragraph 1 shall be user-friendly and allow for the submission of notices exclusively by electronic means. It shall be accessible and visible on the providers' online interface and allow for the submission of notices in at least one of the official languages of the Member State in which the provider is established and in at least one other language that is broadly understood by the largest possible number of speakers in the Union.

## Article 25 - Processing of notices

1. Upon receiving a notice through the mechanisms referred to in Article 24(1), providers of hosting services shall:
   (a) process the notice without undue delay;
   (b) decide whether the information to which the notice relates constitutes illegal content, in accordance with applicable Union law and national law;
   (c) where they decide that the information constitutes illegal content, act expeditiously to remove or to disable access to that information;
   (d) inform without undue delay the individual or entity that submitted the notice of their decision and provide a clear and specific statement of reasons for that decision.